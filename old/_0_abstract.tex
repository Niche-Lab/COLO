\begin{abstract}
Precision livestock farming increasingly relies on advanced object localization techniques to monitor livestock health and optimize resource management. This study introduces COLO (COw LOcalization), a publicly available dataset containing localization data for Jersey and Holstein cows under various lighting conditions and camera angles. We evaluate the performance and generalization capabilities of YOLOv8 and YOLOv9 model variants using this dataset.Our analysis examines model robustness across different lighting and viewpoint configurations and explores the trade-off between model complexity and performance. Our findings indicate that camera viewpoint angle is the most critical factor for model training, surpassing the influence of lighting conditions. Higher model complexity does not necessarily guarantee better results; performance depends on specific data and task requirements. For our dataset, medium complexity models generally outperformed both simpler and more complex models. We also investigate the benefits of initializing weights from models fine-tuned on similar data types compared to using pre-trained weights during fine-tuning. Results show that as training data increases, the advantage of fine-tuned weights diminishes, suggesting that for large datasets, extra fine-tuning may not be necessary. Briefly, our study provides comprehensive insights for animal and dairy scientists to select the optimal model for cow detection, considering factors such as lighting, camera angles, model parameters, dataset size, and weight initialization. These findings enhance the accuracy and efficiency of cow localization technology, contributing significantly to precision livestock farming. The COLO dataset serves as a valuable resource for further advancements in object detection models within this field.
\end{abstract}
\keywords{Object detection \and Cows \and Model generalization \and Model selection}