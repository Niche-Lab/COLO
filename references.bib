

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
YOLO on Agriculture
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{tian2019apple,
  title={Apple detection during different growth stages in orchards using the improved YOLO-V3 model},
  author={Tian, Yunong and Yang, Guodong and Wang, Zhe and Wang, Hao and Li, En and Liang, Zize},
  journal={Computers and electronics in agriculture},
  volume={157},
  pages={417--426},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{lippi2021yolo,
  title={A yolo-based pest detection system for precision agriculture},
  author={Lippi, Martina and Bonucci, Niccol{\`o} and Carpio, Renzo Fabrizio and Contarini, Mario and Speranza, Stefano and Gasparri, Andrea},
  booktitle={2021 29th Mediterranean Conference on Control and Automation (MED)},
  pages={342--347},
  year={2021},
  organization={IEEE}
}

@article{wu2020using,
  title={Using channel pruning-based YOLO v4 deep learning algorithm for the real-time and accurate detection of apple flowers in natural environments},
  author={Wu, Dihua and Lv, Shuaichao and Jiang, Mei and Song, Huaibo},
  journal={Computers and Electronics in Agriculture},
  volume={178},
  pages={105742},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{yang2018real,
  title={Real-time face detection based on YOLO},
  author={Yang, Wang and Jiachun, Zheng},
  booktitle={2018 1st IEEE international conference on knowledge innovation and invention (ICKII)},
  pages={221--224},
  year={2018},
  organization={IEEE}
}


@article{chen2021yolo,
  title={YOLO-face: a real-time face detector},
  author={Chen, Weijun and Huang, Hongbo and Peng, Shuai and Zhou, Changsheng and Zhang, Cuiping},
  journal={The Visual Computer},
  volume={37},
  pages={805--813},
  year={2021},
  publisher={Springer}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
DEEP LEARNING MODELS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%% revie on all yolo models
@article{terven2304comprehensive,
  title={A comprehensive review of YOLO: From YOLOv1 and beyond. arXiv 2023},
  author={Terven, J and Cordova-Esparza, D},
  journal={arXiv preprint arXiv:2304.00501}
}


%%%%%% YOLO NAS

@misc{ultralyticsYOLONASNeural,
	author = {Ultralytics},
	title = {{Y}{O}{L}{O}-{N}{A}{S} ({N}eural {A}rchitecture {S}earch) --- docs.ultralytics.com},
	howpublished = {\url{https://docs.ultralytics.com/models/yolo-nas/}},
	year = {May 2023},
}


%%%%%% YOLO V8

@misc{ultralyticsYOLOv8,
	author = {Ultralytics},
	title = {{Y}{O}{L}{O}v8 --- docs.ultralytics.com},
	howpublished = {\url{https://docs.ultralytics.com/models/yolov8/#overview}},
	year = {Januray 2023},
}

%%%%%% Detr
@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}


@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Transformer in livestock %%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{tangirala2021livestock,
  title={Livestock Monitoring with Transformer},
  author={Tangirala, Bhavesh and Bhandari, Ishan and Laszlo, Daniel and Gupta, Deepak K and Thomas, Rajat M and Arya, Devanshu},
  journal={arXiv preprint arXiv:2111.00801},
  year={2021}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%% Related Work %%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{qiao2019cattle,
  title={Cattle segmentation and contour extraction based on Mask R-CNN for precision livestock farming},
  author={Qiao, Yongliang and Truman, Matthew and Sukkarieh, Salah},
  journal={Computers and Electronics in Agriculture},
  volume={165},
  pages={104958},
  year={2019},
  publisher={Elsevier}
}
%%%%%% pig posture classification using yolo
@article{witte2022introducing,
  title={Introducing a new Workflow for Pig Posture Classification based on a combination of YOLO and EfficientNet},
  author={Witte, Jan-Hendrik and Marx G{\'o}mez, Jorge},
  year={2022}
}
@article{nasirahmadi2019deep,
  title={Deep learning and machine vision approaches for posture detection of individual pigs},
  author={Nasirahmadi, Abozar and Sturm, Barbara and Edwards, Sandra and Jeppsson, Knut-H{\aa}kan and Olsson, Anne-Charlotte and M{\"u}ller, Simone and Hensel, Oliver},
  journal={Sensors},
  volume={19},
  number={17},
  pages={3738},
  year={2019},
  publisher={MDPI}
}
%%%%%%%%%%%% eartag using yolo3
@article{prettonovel,
  title={A novel low-cost visual ear tag based identification system for precision beef cattle livestock farming. Inf. Process. Agric. 2022},
  author={Pretto, A and Savio, G and Gottardo, F and Uccheddu, F and Concheri, G},
  journal={Press.[Google Scholar]}
}
@inproceedings{zin2020cow,
  title={Cow identification system using ear tag recognition},
  author={Zin, Thi Thi and Misawa, Shuhei and Pwint, Moe Zet and Thant, Shin and Seint, Pann Thinzar and Sumi, Kosuke and Yoshida, Kyohiro},
  booktitle={2020 IEEE 2nd Global Conference on Life Sciences and Technologies (LifeTech)},
  pages={65--66},
  year={2020},
  organization={IEEE}
}
%%%%%%%%%%% feeding behavior using yolo
@article{yu2022automatic,
  title={Automatic detection method of dairy cow feeding behaviour based on YOLO improved model and edge computing},
  author={Yu, Zhenwei and Liu, Yuehua and Yu, Sufang and Wang, Ruixue and Song, Zhanhua and Yan, Yinfa and Li, Fade and Wang, Zhonghua and Tian, Fuyang},
  journal={Sensors},
  volume={22},
  number={9},
  pages={3271},
  year={2022},
  publisher={MDPI}
}
%%%%%%%% coco dataset
@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}
%%%%%%%% VGG_16
@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}
%%%%%%%%%%%% resnet 152
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
%%%%%%%%%% transformer

@inproceedings{dai2021dynamic,
  title={Dynamic detr: End-to-end object detection with dynamic attention},
  author={Dai, Xiyang and Chen, Yinpeng and Yang, Jianwei and Zhang, Pengchuan and Yuan, Lu and Zhang, Lei},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2988--2997},
  year={2021}
}

%%%%%%%%% YOLO map paramter table
@misc{map-param,
	author = {},
	title = {},
	howpublished = {\url{%https://github.com/ultralytics/ultralytics#:~:text=TensorRT%0A(ms)-,params%0A(M),-FLOPs%0A(B)}},
	year = {},
	note = {[Accessed 02-11-2023]},
}

%%%%%%%%%%% YOLOv9 %%%%%%%%%%%%
@article{wang2024yolov9,
  title={{YOLOv9}: Learning What You Want to Learn Using Programmable Gradient Information},
  author={Wang, Chien-Yao  and Liao, Hong-Yuan Mark},
  booktitle={arXiv preprint arXiv:2402.13616},
  year={2024}
}

%%%%%%%%%%% Dr Chen's References.bib %%%%%%%%%%%%

@inproceedings{kour2014real,
  title        = {Real-time segmentation of on-line handwritten arabic script},
  author       = {Kour, George and Saabne, Raid},
  booktitle    = {Frontiers in Handwriting Recognition (ICFHR), 2014 14th International Conference on},
  pages        = {417--422},
  year         = {2014},
  organization = {IEEE}
}

@inproceedings{kour2014fast,
  title        = {Fast classification of handwritten on-line Arabic characters},
  author       = {Kour, George and Saabne, Raid},
  booktitle    = {Soft Computing and Pattern Recognition (SoCPaR), 2014 6th International Conference of},
  pages        = {312--318},
  year         = {2014},
  organization = {IEEE}
}

@article{hadash2018estimate,
  title   = {Estimate and Replace: A Novel Approach to Integrating Deep Neural Networks with Existing Applications},
  author  = {Hadash, Guy and Kermany, Einat and Carmeli, Boaz and Lavi, Ofer and Kour, George and Jacovi, Alon},
  journal = {arXiv preprint arXiv:1804.09028},
  year    = {2018}
}

%%%%%%%%%%%%% yolo v1%%%%%%%%%%%%%%%%
@inproceedings{redmon2016you,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={779--788},
  year={2016}
}
%%%%%%%%%%%% yolov2%%%%%%%%%%%
@inproceedings{redmon2017yolo9000,
  title={YOLO9000: better, faster, stronger},
  author={Redmon, Joseph and Farhadi, Ali},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7263--7271},
  year={2017}
}
%%%%%%%%%%%%%%% yolo v3 %%%%%%%%%%%%%%%%
@article{redmon2018yolov3,
  title={Yolov3: An incremental improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal={arXiv preprint arXiv:1804.02767},
  year={2018}
}
%%%%%%%%%%% yolov4%%%%%%%%%%%%
@article{bochkovskiy2020yolov4,
  title={Yolov4: Optimal speed and accuracy of object detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2004.10934},
  year={2020}
}

%%%%%%%%%% yolov5 %%%%%%%%%%%
@misc{Jocher2020YOLOv5,
  author = {Jocher, Glenn},
  title = {{YOLOv5 by Ultralytics}},
  year = {2020},
  howpublished = {\url{https://github.com/ultralytics/yolov5}},
  note = {Accessed on: 28 February 2023}
}
%%%%%%%%%%% yolov6 %%%%%
@article{li2022yolov6,
  title={YOLOv6: A single-stage object detection framework for industrial applications},
  author={Li, Chuyi and Li, Lulu and Jiang, Hongliang and Weng, Kaiheng and Geng, Yifei and Li, Liang and Ke, Zaidan and Li, Qingyuan and Cheng, Meng and Nie, Weiqiang and others},
  journal={arXiv preprint arXiv:2209.02976},
  year={2022}
}
%%%%%%%%%%% yolov7 %%%%%%%%%
@inproceedings{wang2023yolov7,
  title={YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors},
  author={Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7464--7475},
  year={2023}
}


%## Bottolneck Principle

@inproceedings{tishby2015deep,
  title={Deep learning and the information bottleneck principle},
  author={Tishby, Naftali and Zaslavsky, Noga},
  booktitle={2015 ieee information theory workshop (itw)},
  pages={1--5},
  year={2015},
  organization={IEEE}
}

@article{tishby2000information,
  title={The information bottleneck method},
  author={Tishby, Naftali and Pereira, Fernando C and Bialek, William},
  journal={arXiv preprint physics/0004057},
  year={2000}
}

%### Silu
@article{elfwing2018sigmoid,
  title={Sigmoid-weighted linear units for neural network function approximation in reinforcement learning},
  author={Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  journal={Neural networks},
  volume={107},
  pages={3--11},
  year={2018},
  publisher={Elsevier}
}
######## Resnet
@article{targ2016resnet,
  title={Resnet in resnet: Generalizing residual architectures},
  author={Targ, Sasha and Almeida, Diogo and Lyman, Kevin},
  journal={arXiv preprint arXiv:1603.08029},
  year={2016}
}

########### 
@misc{mmyolo2023,
  author = {{Contributors, M.}},
  title = {{YOLOv8 by MMYOLO}},
  year = {2023},
  howpublished = {\url{https://github.com/open-mmlab/mmyolo/tree/main/configs/yolov8}},
  note = {Accessed on 13 May 2023}
}
######## anncr-free

@inproceedings{law2018cornernet,
  author = {Law, H. and Deng, J.},
  title = {Cornernet: Detecting objects as paired keypoints},
  booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
  pages = {734--750},
  year = {2018},
  address = {Munich, Germany},
  month = {8--14 September}
}

@inproceedings{duan2019centernet,
  author = {Duan, K. and Bai, S. and Xie, L. and Qi, H. and Huang, Q. and Tian, Q.},
  title = {Centernet: Keypoint triplets for object detection},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages = {6569--6578},
  year = {2019},
  address = {Seoul, Republic of Korea},
  month = {27 October--2 November}
}

@inproceedings{tian2019fcos,
  author = {Tian, Z. and Shen, C. and Chen, H. and He, T.},
  title = {Fcos: Fully convolutional one-stage object detection},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages = {9627--9636},
  year = {2019},
  address = {Seoul, Republic of Korea},
  month = {27 October--2 November}
}
############# Auxiliary Supervision
@inproceedings{Lee2015DeeplySupervised,
  author = {Lee, Chen-Yu and Xie, Saining and Gallagher, Patrick and Zhang, Zhengyou and Tu, Zhuowen},
  title = {Deeply-supervised Nets},
  booktitle = {Artificial Intelligence and Statistics},
  pages = {562--570},
  year = {2015},
  note = {Sections referenced: 1, 2, 3}
}

@article{wang2015training,
  title={Training deeper convolutional networks with deep supervision},
  author={Wang, Liwei and Lee, Chen-Yu and Tu, Zhuowen and Lazebnik, Svetlana},
  journal={arXiv preprint arXiv:1505.02496},
  year={2015}
}
@inproceedings{Szegedy2015GoingDeeper,
  author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  title = {Going Deeper with Convolutions},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages = {1--9},
  year = {2015},
  note = {Sections referenced: 1, 2, 3}
}
%%%%%%% cow Segmentation and Classification %%%%%%%
@article{noe2022automatic,
  title={Automatic detection and tracking of mounting behavior in cattle using a deep learning-based instance segmentation model},
  author={Noe, Su Myat and Zin, Thi Thi and Tin, Pyke and Kobayashi, Ikuo},
  journal={Int. J. Innov. Comput. Inf. Control},
  volume={18},
  number={1},
  pages={211--220},
  year={2022}
}
 %%%%%%%%%%%%% cow tracking using CNN
@article{guzhva2018now,
  title={Now you see me: Convolutional neural network based tracker for dairy cows},
  author={Guzhva, Oleksiy and Ard{\"o}, H{\aa}kan and Nilsson, Mikael and Herlin, Anders and Tufvesson, Linda},
  journal={Frontiers in Robotics and AI},
  volume={5},
  pages={107},
  year={2018},
  publisher={Frontiers Media SA}
}
@article{poursaberi2010real,
  title={Real-time automatic lameness detection based on back posture extraction in dairy cattle: Shape analysis of cow with image processing techniques},
  author={Poursaberi, Ahmad and Bahr, Claudia and Pluk, Arno and Van Nuffel, Annelies and Berckmans, Daniel},
  journal={Computers and electronics in agriculture},
  volume={74},
  number={1},
  pages={110--119},
  year={2010},
  publisher={Elsevier}
}
%%%%%%%%%% cow pose estimation
@article{li2019deep,
  title={Deep cascaded convolutional models for cattle pose estimation},
  author={Li, Xiangyuan and Cai, Cheng and Zhang, Ruifei and Ju, Lie and He, Jinrong},
  journal={Computers and Electronics in Agriculture},
  volume={164},
  pages={104885},
  year={2019},
  publisher={Elsevier}
}
%%%%%%%%%%% cow segmentation and dectection
@article{salau2020instance,
  title={Instance segmentation with Mask R-CNN applied to loose-housed dairy cows in a multi-camera setting},
  author={Salau, Jennifer and Krieter, Joachim},
  journal={Animals},
  volume={10},
  number={12},
  pages={2402},
  year={2020},
  publisher={MDPI}
}

%%%%%%%%%%% pig segmentation and detection
@article{tu2021automatic,
  title={Automatic detection and segmentation for group-housed pigs based on PigMS R-CNN},
  author={Tu, Shuqin and Yuan, Weijun and Liang, Yun and Wang, Fan and Wan, Hua},
  journal={Sensors},
  volume={21},
  number={9},
  pages={3251},
  year={2021},
  publisher={MDPI}
}



%%%%%%%%%% pig detection and posture estimation
@article{riekert2020automatically,
  title={Automatically detecting pig position and posture by 2D camera imaging and deep learning},
  author={Riekert, Martin and Klein, Achim and Adrion, Felix and Hoffmann, Christa and Gallmann, Eva},
  journal={Computers and Electronics in Agriculture},
  volume={174},
  pages={105391},
  year={2020},
  publisher={Elsevier}
}
%%%%%%%%%%%%%%%% COLO dataset%%%%%%%%%%%
@misc{COLODataset2023,
  title        = {COLO: A Large-scale Dataset for Conversational Question Answering over Knowledge Graphs},
  howpublished = {\url{https://huggingface.co/datasets/Niche-Squad/COLO}},
  year         = {2023},
  note         = {Accessed: 2024-04-09}
}
%%%%%%%%% monitoring cow behavior%%%%%%
@article{wu2023monitoring,
  title={Monitoring the respiratory behavior of multiple cows based on computer vision and deep learning},
  author={Wu, Dihua and Han, Mengxuan and Song, Huaibo and Song, Lei and Duan, Yuanchao},
  journal={Journal of Dairy Science},
  volume={106},
  number={4},
  pages={2963--2979},
  year={2023},
  publisher={Elsevier}
}
%%%%%%%%%%%% papers monitoring health
@article{morrone2022industry,
  title={Industry 4.0 and precision livestock farming (PLF): an up to date overview across animal productions},
  author={Morrone, Sarah and Dimauro, Corrado and Gambella, Filippo and Cappai, Maria Grazia},
  journal={Sensors},
  volume={22},
  number={12},
  pages={4319},
  year={2022},
  publisher={MDPI}
}

@article{hao2023cattle,
  title={Cattle body detection based on YOLOv5-EMA for precision livestock farming},
  author={Hao, Wangli and Ren, Chao and Han, Meng and Zhang, Li and Li, Fuzhong and Liu, Zhenyu},
  journal={Animals},
  volume={13},
  number={22},
  pages={3535},
  year={2023},
  publisher={MDPI}
}
%%%%%%%%% Cv in animal science%%%%%%
@article{fernandes2020image,
  title={Image analysis and computer vision applications in animal sciences: an overview},
  author={Fernandes, Arthur Francisco Ara{\'u}jo and D{\'o}rea, Jo{\~a}o Ricardo Rebou{\c{c}}as and Rosa, Guilherme Jord{\~a}o de Magalh{\~a}es},
  journal={Frontiers in Veterinary Science},
  volume={7},
  pages={551269},
  year={2020},
  publisher={Frontiers Media SA}
}
%%%%%%%%%%segmentation
@inproceedings{hariharan2015hypercolumns,
  title={Hypercolumns for object segmentation and fine-grained localization},
  author={Hariharan, Bharath and Arbel{\'a}ez, Pablo and Girshick, Ross and Malik, Jitendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={447--456},
  year={2015}
}
%%%%%%%%%%%% segmentation and pose estimatin
@inproceedings{hu2019segmentation,
  title={Segmentation-driven 6d object pose estimation},
  author={Hu, Yinlin and Hugonot, Joachim and Fua, Pascal and Salzmann, Mathieu},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3385--3394},
  year={2019}
}
@article{girshick2015region,
  title={Region-based convolutional networks for accurate object detection and segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={38},
  number={1},
  pages={142--158},
  year={2015},
  publisher={IEEE}
}
@article{li2021practices,
  title={Practices and applications of convolutional neural network-based computer vision systems in animal farming: A review},
  author={Li, Guoming and Huang, Yanbo and Chen, Zhiqian and Chesser Jr, Gary D and Purswell, Joseph L and Linhoss, John and Zhao, Yang},
  journal={Sensors},
  volume={21},
  number={4},
  pages={1492},
  year={2021},
  publisher={MDPI}
}
@article{zin_automatic_2020,
	title = {Automatic {Cow} {Location} {Tracking} {System} {Using} {Ear} {Tag} {Visual} {Analysis}},
	volume = {20},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/12/3564},
	doi = {10.3390/s20123564},
	abstract = {Nowadays, for numerous reasons, smart farming systems focus on the use of image processing technologies and 5G communications. In this paper, we propose a tracking system for individual cows using an ear tag visual analysis. By using ear tags, the farmers can track specific data for individual cows such as body condition score, genetic abnormalities, etc. Specifically, a four-digit identification number is used, so that a farm can accommodate up to 9999 cows. In our proposed system, we develop an individual cow tracker to provide effective management with real-time upgrading enforcement. For this purpose, head detection is first carried out to determine the cow’s position in its related camera view. The head detection process incorporates an object detector called You Only Look Once (YOLO) and is then followed by ear tag detection. The steps involved in ear tag recognition are (1) finding the four-digit area, (2) digit segmentation using an image processing technique, and (3) ear tag recognition using a convolutional neural network (CNN) classifier. Finally, a location searching system for an individual cow is established by entering the ID numbers through the application’s user interface. The proposed searching system was confirmed by performing real-time experiments at a feeding station on a farm at Hokkaido prefecture, Japan. In combination with our decision-making process, the proposed system achieved an accuracy of 100\% for head detection, and 92.5\% for ear tag digit recognition. The results of using our system are very promising in terms of effectiveness.},
	language = {en},
	number = {12},
	urldate = {2024-04-05},
	journal = {Sensors},
	author = {Zin, Thi Thi and Pwint, Moe Zet and Seint, Pann Thinzar and Thant, Shin and Misawa, Shuhei and Sumi, Kosuke and Yoshida, Kyohiro},
	month = jan,
	year = {2020},
	note = {Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {convolutional neural network, digit segmentation, ear tag recognition, location searching, object detector},
	pages = {3564},
	file = {Full Text PDF:/Users/niche/Zotero/storage/DRFPLKY9/Zin et al. - 2020 - Automatic Cow Location Tracking System Using Ear T.pdf:application/pdf},
}
%%%%%%%%% YOLO data formate
@misc{ultralytics2023datasets,
  author = {Ultralytics},
  title = {Ultralytics Datasets Documentation},
  year = {2023},
  howpublished = {\url{https://docs.ultralytics.com/datasets/detect/}},
 
}
%%%%%%%% lableme
@misc{labelme2023,
  author = {{Massachusetts Institute of Technology}},
  title = {LabelMe: Image Annotation Tool},
  year = {2023},
  howpublished = {\url{http://labelme.csail.mit.edu/Release3.0/}},
  
}
%%%%%%%%%%%% CVAT
@misc{cvat2023,
  author = {{OpenCV}},
  title = {CVAT: Computer Vision Annotation Tool},
  year = {2023},
  howpublished = {\url{https://www.cvat.ai/}},
  
}
%%%%%%%%%% roboflow
@misc{roboflow2023,
  author = {{Roboflow}},
  title = {Roboflow: Organize, Annotate, and Improve Machine Learning Datasets},
  year = {2023},
  howpublished = {\url{https://roboflow.com/}},
  
}
%%5%%%%model complexity
@article{hu2021model,
  title={Model complexity of deep learning: A survey},
  author={Hu, Xia and Chu, Lingyang and Pei, Jian and Liu, Weiqing and Bian, Jiang},
  journal={Knowledge and Information Systems},
  volume={63},
  pages={2585--2619},
  year={2021},
  publisher={Springer}
}
%%%%%%%%computational cost
@inproceedings{justus2018predicting,
  title={Predicting the computational cost of deep learning models},
  author={Justus, Daniel and Brennan, John and Bonner, Stephen and McGough, Andrew Stephen},
  booktitle={2018 IEEE international conference on big data (Big Data)},
  pages={3873--3882},
  year={2018},
  organization={IEEE}
}
%%%%%%% imagenet
@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}
%%%%%% alexnet %%%%%%%%%%%%
@article{krizhevsky2017imagenet,
  title={ImageNet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Communications of the ACM},
  volume={60},
  number={6},
  pages={84--90},
  year={2017},
  publisher={AcM New York, NY, USA}
}
%%%%%%%%%%%%%googlenet
@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}
%%%%%%%%%%%%% VGG%%%%%%%%%%
@article{karen2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Karen, Simonyan},
  journal={arXiv preprint arXiv: 1409.1556},
  year={2014}
}
%%%%%%%%%%%%% densnet%%%%%%%%%%
@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}
%%%%%%%%% cattle eye view dataset%%%%
@inproceedings{ong2023cattleeyeview,
  title={CattleEyeView: A Multi-task Top-down View Cattle Dataset for Smarter Precision Livestock Farming},
  author={Ong, Kian Eng and Retta, Sivaji and Srinivasan, Ramarajulu and Tan, Shawn and Liu, Jun},
  booktitle={2023 IEEE International Conference on Visual Communications and Image Processing (VCIP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}
@article{t2020long,
  title={Long-term tracking of group-housed livestock using keypoint detection and map estimation for individual animal identification},
  author={T. Psota, Eric and Schmidt, Ty and Mote, Benny and C. P{\'e}rez, Lance},
  journal={Sensors},
  volume={20},
  number={13},
  pages={3670},
  year={2020},
  publisher={MDPI}
}
%%%%%%%%%% finituning%%%%%%%%%%%
@article{han2021pre,
  title={Pre-trained models: Past, present and future},
  author={Han, Xu and Zhang, Zhengyan and Ding, Ning and Gu, Yuxian and Liu, Xiao and Huo, Yuqi and Qiu, Jiezhong and Yao, Yuan and Zhang, Ao and Zhang, Liang and others},
  journal={AI Open},
  volume={2},
  pages={225--250},
  year={2021},
  publisher={Elsevier}
}
@inproceedings{guirguis2022cfa,
  title={Cfa: Constraint-based finetuning approach for generalized few-shot object detection},
  author={Guirguis, Karim and Hendawy, Ahmed and Eskandar, George and Abdelsamad, Mohamed and Kayser, Matthias and Beyerer, J{\"u}rgen},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4039--4049},
  year={2022}
}
@article{gupta2023novel,
  title={A novel finetuned YOLOv6 transfer learning model for real-time object detection},
  author={Gupta, Chhaya and Gill, Nasib Singh and Gulia, Preeti and Chatterjee, Jyotir Moy},
  journal={Journal of Real-Time Image Processing},
  volume={20},
  number={3},
  pages={42},
  year={2023},
  publisher={Springer}
}
}%%%%%%%%%%%%%%
@misc{image2023,
  title = {Title of Image},
  author = {Author or Organization},
  year = {2023},
  howpublished = {\url{https://user-images.githubusercontent.com/27466624/222869864-1955f054-aa6d-4a80-aed3-92f30af28849.jpg}},
  
}
%%%%%%%%%%%%%%
@misc{v8yaml,
  title = {Ultralytics v8 models},
  year = {2023},
  howpublished = {\url{https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/models/v8/yolov8.yaml}},
}

@misc{v9yaml,
  title = {Ultralytics v9 models},
  year = {2023},
  howpublished = {\url{https://github.com/ultralytics/ultralytics/tree/main/ultralytics/cfg/models/v9}},
}
%%%%%%%%%% opencow public dataset
@misc{ visualization-tools-for-opencows2020-dataset,
  title = { Visualization Tools for OpenCow2020 Dataset },
  type = { Computer Vision Tools },
  author = { Dataset Ninja },
  howpublished = { \url{ https://datasetninja.com/opencows2020 } },
  url = { https://datasetninja.com/opencows2020 },
  journal = { Dataset Ninja },
  publisher = { Dataset Ninja },
  year = { 2024 },
  month = { may },
  note = { visited on 2024-05-21 },
}
%%%%%%%%%% API
@misc{greif_dgreifring_2024,
	title = {dgreif/ring},
	copyright = {MIT},
	url = {https://github.com/dgreif/ring},
	abstract = {Unofficial packages for Ring Doorbells, Cameras, Alarm System, and Smart Lighting},
	urldate = {2024-04-23},
	author = {Greif, Dusty},
	month = apr,
	year = {2024},
	note = {original-date: 2018-10-12T22:53:01Z},
	keywords = {alarm, homebridge, homebridge-plugin, homekit, ring},
}
%%%%%%%%%%% ultralitic website %%%%%%%%%
@misc{ultralytics,
  author = {Ultralytics},
  title = {Ultralytics Models Documentation},
  
  howpublished = {\url{https://docs.ultralytics.com/models/}},
  note = {Accessed: 2024-05-21}
}
%%%%%%% bounding box%%%%
@inproceedings{viola2001rapid,
  title={Rapid object detection using a boosted cascade of simple features},
  author={Viola, Paul and Jones, Michael},
  booktitle={Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition. CVPR 2001},
  volume={1},
  pages={I--I},
  year={2001},
  organization={Ieee}
}
%%%%%%%%%% drnyolo
@article{xu2020improved,
  title={Improved YOLO-V3 with DenseNet for multi-scale remote sensing target detection},
  author={Xu, Danqing and Wu, Yiquan},
  journal={Sensors},
  volume={20},
  number={15},
  pages={4276},
  year={2020},
  publisher={MDPI}
}
%%%%%%%%%ms rcnnn
@inproceedings{huang2019mask,
  title={Mask scoring r-cnn},
  author={Huang, Zhaojin and Huang, Lichao and Gong, Yongchao and Huang, Chang and Wang, Xinggang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6409--6418},
  year={2019}
}

%%%%%%% mask rcnn
@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}
%%%%%%%% fast rcnn
@inproceedings{girshick2015fast,
  title={Fast r-cnn},
  author={Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1440--1448},
  year={2015}
}
%%%%%%%%%% SSD
@inproceedings{liu2016ssd,
  title={Ssd: Single shot multibox detector},
  author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part I 14},
  pages={21--37},
  year={2016},
  organization={Springer}
}
%%% unet
@article{siddique2021u,
  title={U-net and its variants for medical image segmentation: A review of theory and applications},
  author={Siddique, Nahian and Paheding, Sidike and Elkin, Colin P and Devabhaktuni, Vijay},
  journal={Ieee Access},
  volume={9},
  pages={82031--82057},
  year={2021},
  publisher={IEEE}
}
%%%% super animal
@article{ye2022superanimal,
  title={SuperAnimal pretrained pose estimation models for behavioral analysis},
  author={Ye, Shaokai and Filippova, Anastasiia and Lauer, Jessy and Schneider, Steffen and Vidal, Maxime and Qiu, Tian and Mathis, Alexander and Mathis, Mackenzie Weygandt},
  journal={arXiv preprint arXiv:2203.07436},
  year={2022}
}
%%%%%%%%%%%%% datasets python package %%%%%%%%%%
% Add the following entry in your bibliography file (.bib)
@misc{datasets,
  author = {Lhoest, Quentin and Villanova del Moral, Albert and Jernite, Yacine and Thakur, Abhishek and von Platen, Patrick and Patil, Suraj and Chaumond, Julien and Drame, Mariama and Plu, Julien and Tunstall, Lewis and Davison, Joe and {\v{C}}uklina, Marija and Brandeis, Simon and Le Scao, Teven and Schmid, Philipp and Gugger, Sylvain and Delangue, Cl{\'{e}}ment and Matussi{\`{e}}re, Th{\'{e}}o and Debut, Lysandre and Ben-Ami, Idan and Filippova, Olga and d'Hoffschmidt, Martin and G{\'{e}}rard, Sebastien and Lane, Brendan and Ansell, Leo and Buitinck, Lars and Esposito, Damien and Raison, Mathis and Klein, Jacob and Nguyen, Thibault and Mikami, Tomoki and Sanh, Victor and Chaudhary, Vishrav and Patry, Nicolas and Chang, Wilson Y. and Froment, Julien and Buhmann, Jonas and Malartic, Quentin and Winschel, Victor and Watson, Charlie and Pradeep, Rajarshi and Chhablani, Gunjan and Rohrbach, Manuela and Jenny, Maxim and Bolton, John and Phang, Jason and Löw, Theo and Rush, Alexander and Wolf, Thomas},
  title = {Datasets: A Community Library for Natural Language Processing},
  year = {2021},
  publisher = {GitHub},
  howpublished = {\url{https://github.com/huggingface/datasets}},
}
%%%%%%%%%% computational resources
@misc{notebookcheck_m1_max,
    author = {Andreas Osthoff},
    title = {Apple’s M1 Max GPU is as powerful as an Nvidia RTX 2080 desktop GPU and the Sony PS5 gaming console},
    howpublished = {\url{https://www.notebookcheck.net/Apple-s-M1-Max-GPU-is-as-powerful-as-an-Nvidia-RTX-2080-desktop-GPU-and-the-Sony-PS5-gaming-console.573846.0.html#:~:text=Yet\%2C\%20the\%2032\%2Dcore\%20GPU,of\%20battery\%20life\%20as\%20well}},
    year = {2021},
    note = {Accessed: 2024-07-07}
}
@misc{nvidia_a100,
    author = {NVIDIA Corporation},
    title = {NVIDIA A100 Tensor Core GPU},
    howpublished = {\url{https://www.nvidia.com/en-us/data-center/a100/}},
    note = {Accessed: 2024-07-07}
}
