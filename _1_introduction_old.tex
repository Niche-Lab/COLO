\section{Introduction}

%%% Motivation 
The precise enumeration of cattle within pastoral environments is imperative for enhancing farm operational efficiency, exerting a significant influence on both the economic and ecological aspects of livestock management. Accurate cattle detection is a linchpin in the execution of strategic farm management, impacting resource allocation, health surveillance, and breeding practices. The advent of Computer Vision (CV) and Artificial Intelligence (AI) technologies in cattle detection systems has been revolutionary for agricultural methodologies. These innovations facilitate the automated monitoring of cattle, providing real-time, high-precision counts, while mitigating manual labor and its inherent inaccuracies. CV-driven AI algorithms are adept at identifying individual cattle amidst the complexity of farm settings, adjusting for variations in illumination, visual obstructions, and animal movement.

A salient application of such technology is evident in the optimization of alley flushing mechanisms within modern dairy operations. Preserving alley cleanliness is essential for averting diseases like mastitis, which can substantially affect both dairy output and bovine well-being. Traditional manual flushing, typically performed bi-daily, suffers from inefficiencies and a lack of responsiveness to the alley's dynamic conditions. The predetermined flushing schedules may not align with the actual sanitary requirements, potentially compromising cleanliness or wasting water. An AI system, empowered by computer vision, can refine this process by determining the optimal flushing moments. For instance, by detecting the number of cows present and initiating the flush when animal counts drop below a specific threshold—ideally when no cows are present—the system ensures a timely and efficient cleaning without human intervention. This not only conserves resources but also upholds a consistently hygienic environment conducive to animal health and productivity.


%%% Application of animal science and agriculture
Animal scientists are increasingly leveraging AI-based object detection algorithms, such as those employed in recognizing cows, pigs, and sheep, for a plethora of purposes. Such as, classifying pig postures segmenting cattle instances, monitoring cow feeding behavior etc. Predominantly, research has focused on deploying various deep learning models to address different challenges within the domain. The utility of YOLO (You Only Look Once) models, in particular, transcends traditional object detection boundaries. These models have been adeptly applied in the agricultural sector for purposes such as identifying and classifying different crop types \cite{tian2019apple,lippi2021yolo}, as well as detecting pests and plant diseases \cite{wu2020using}, significantly contributing to the progress of precision agriculture and fostering the movement towards automated farming operations. Similarly, in the realm of biometrics and security, the flexibility of YOLO frameworks has been exploited for facial detection tasks, thus becoming a cornerstone for the enhancement of facial recognition technologies \cite{yang2018real,chen2021yolo}. This multifaceted applicability of YOLO models underscores their versatility and potency in propelling forward a wide array of intelligent systems across diverse sectors.

A recent study introduced a method to accurately classify the posture of pigs based on images. They used YOLOv5, which achieved a pig detection accuracy of 0.994 with an APIoU=0.5. Then they utilized EfficientNet to classify the detected pigs into 'lying' and 'notLying' postures achieving a precision rate of 0.93. This innovative approach demonstrated the advantages of using models, for classifying pig posture resulting in improvements, in accuracy. These studies have addressed the issue that researchers aimed to solve \cite{witte2022introducing}. Another recent advancement in precision livestock farming offers a cost-effective way to identify and monitor beef cattle using everyday surveillance cameras. This method can pinpoint cattle ear tags and even track their drinking behaviors, with the capability to read cow IDs with an impressive 89\% accuracy. Such innovations not only streamline cattle management but also have the potential to significantly reduce monitoring costs for farmers \cite{prettonovel}.

However, the costs, including labor, time, and computational resources, to implement the object detection were rarely addressed. For example, researchers conducted a study, on precision dairy farming, in Hokkaido, Japan. They successfully developed a system that could recognize cows ear tags using the object detector. To achieve this they needed a dataset of 20,000 training samples that were specifically focused on detecting cow heads \cite{zin2020cow}. Preparing this amount of samples can be labor-intesntive, as formatting and labeling the positions of each object in an image requires professional training in programming language. For example, COCO annotation \cite{lin2014microsoft} format is the most common format for object detection. It requires organizing the coordinates of the bounding box, the class of the object, and the image size in a JSON file. Without related expertise, there is a barrier to implement object detection in animal and dairy sciences. Another obstacle of the implementation is the computational resources. Not every computer can implement the modern object detection models, which have millions of parameters and requires up to 12 GB of video memory. For instance, the VGG-16 model \cite{simonyan2014very} has 138 million parameters and recommends a VRAM of at least 8GB, while the ResNet-152 \cite{he2016deep} has around 60 million parameters with a recommended VRAM of 11GB. Hence, knowing the computational cost is also an important factor for researchers to consider when implementing object detection. Lastly, the transfer-ability of the published studies is always missed to be discussed. This factor is important when one research want to reproduce the same published work in their own research, which may have different lighting or environment that affects the model performance. Transferring the model to a new environment usually requires providing additional training efforts, which is also a cost to consider.

Impressive results have been achieved using models such as YOLOv5 \cite{witte2022introducing} Mask R CNN \cite{qiao2019cattle} and DRN YOLO based on YOLOv4 \cite{zin2020cow}. These approaches have proven successful in detecting postures performing segmentation and extracting useful features in complex farm environments. 

%%%%%%%%%%%%% example of related work on cow
\colorbox{yellow}{%
    \parbox{\dimexpr\textwidth-2\fboxsep\relax}{%
        Example of cow tracking \cite{guzhva2018now}, Example of cow segmentation and detection \cite{salau2020instance}, cattle pose estimation \cite{li2019deep}%
    }%
}
%%%%%%%%%%%% example on pig
\colorbox{yellow}{%
    \parbox{\dimexpr\textwidth-2\fboxsep\relax}{%
        Example for pig segmentation and detection \cite{tu2021automatic}, example for pig detection and posture estimation \cite{riekert2020automatically}%
    }%
}



Despite the promising advancements, the implementation of AI and CV technologies in animal science, particularly in precision livestock farming, faces significant challenges. High computational costs, the need for extensive training datasets, and the expertise required for data annotation are notable barriers that hinder the widespread adoption of these technologies. Additionally, the transferability of models across different environmental conditions remains a critical issue, as variations in lighting and camera settings can drastically affect model performance.

Addressing these challenges, our research introduces the "COWS ONLY LIVE ONCE (COLO)" dataset, an open-access resource designed to investigate the generalization capabilities of AI models in localizing indoor cows. By focusing on indoor environments, where conditions can be tightly controlled and monitored, this study aims to enhance the accuracy and reliability of livestock recognition tasks. Leveraging advanced AI models such as YOLOv8, YOLONAS, and YOLO V9, our work not only seeks to push the boundaries of what is currently achievable in livestock detection but also to facilitate the adoption of cutting-edge technologies in the animal sciences sector. Through the development of the COLO dataset, we address critical gaps in the field, such as the need for large, annotated datasets and the challenge of model transferability, paving the way for more efficient, responsive, and cost-effective livestock management solutions.


\subsection{Problem Statements and Contribution}
While notable advancements in object detection have been made within the domains of animal science and agriculture, our research endeavors to bridge certain gaps that remain unaddressed.

A critical concern is the determination of the necessary quantity of training samples to attain high accuracy, as measured by the Mean Average Precision (MAP). While it is common for researchers to gather data and fine-tune pre-trained models to secure MAP values exceeding $95\%$, the ideal dataset size for achieving such accuracy without incurring unnecessary computational costs remains undetermined. Excessive data may lead to computational redundancy, while insufficient data could result in diminished accuracy.

Moreover, the problem of optimal model selection poses another significant challenge. The spectrum of model complexity ranges from the highly intricate, such as YOLOv8x, which consists 68.2 million parameters ~\cite{map-param}, to more streamlined variants like YOLOv8n with its 3.2 million parameters. As indicated in Table~\ref{table:model-map-param}, YOLOv8x outperforms YOLOv8n with a notable higher MAP value of 53.9 compared to 37.3, respectively. This disparity might incline researchers toward selecting the more complex YOLOv8x due to its superior MAP. Nevertheless, this decision comes with trade-offs: models with a greater number of parameters, while more accurate, demand extensive computational resources, including higher memory usage. Conversely, models with fewer parameters are typically quicker to train, are more memory-efficient, but offer less precision. The pivotal question we seek to answer is whether the efficacy of a complex model over a simpler one persists when the scope of classes is narrower, such as in datasets unlike COCO, and what the implications are when fine-tuning models for these scenarios.
